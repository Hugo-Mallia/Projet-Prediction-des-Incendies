from fastapi import FastAPI, Request
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from app.routes.scan_environment import router as scan_router
from app.routers.items import router as items_router
from app.services.audit_service import evaluate_audit

import gradio as gr
from dotenv import load_dotenv
import os
import re

from langchain_core.messages import HumanMessage, AIMessage
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder
)
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI

# Chargement des variables d'environnement
load_dotenv()

app = FastAPI()

# Mount static files
app.mount("/static", StaticFiles(directory="static"), name="static")

# Setup templates
templates = Jinja2Templates(directory="templates")

# Ajouter les routers API
app.include_router(scan_router, prefix="/api")
app.include_router(items_router, prefix="/api")

@app.get("/")
async def root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

def audit_chatbot():
    questions = [
        ("Bonjour, je suis Flam√©o, votre auditeur s√©curit√© incendie. Pour commencer, quel est le nom du b√¢timent √† auditer ?", "buildingName"),
        ("Merci. Quel est le type de b√¢timent (immeuble, maison, entrep√¥t, usine, √©tablissement public) ?", "buildingType"),
        ("Tr√®s bien. Quel est l'usage principal du b√¢timent (professionnel ou personnel) ?", "buildingUsage"),
        ("Pouvez-vous m'indiquer la taille du b√¢timent en m¬≤ ?", "buildingSize"),
        ("Combien d'extincteurs sont pr√©sents dans le b√¢timent ?", "fireExtinguishers"),
        ("Combien de sorties de secours sont disponibles ?", "emergencyExits"),
        ("Combien de d√©tecteurs de fum√©e sont install√©s ?", "smokeDetectors"),
        ("Quelle est la date du dernier exercice d'√©vacuation (AAAA-MM-JJ) ?", "fireDrills"),
        ("Combien de pi√®ces compte le b√¢timent ?", "roomCount"),
        ("Merci. Quelle est la taille de chaque pi√®ce (en m¬≤, s√©par√©es par des virgules) ?", "roomSizes"),
        ("Quels sont les mat√©riaux de construction principaux ?", "constructionMaterials"),
        ("Un plan d'√©vacuation est-il disponible et affich√© (oui/non) ?", "evacuationPlan"),
        ("Combien de sessions de formation en s√©curit√© incendie ont eu lieu cette ann√©e ?", "trainingSessions"),
        ("Sur une √©chelle de 1 √† 5, quel est le niveau de sensibilisation du personnel √† la s√©curit√© incendie ?", "staffAwareness"),
    ]

    llm = ChatOpenAI(
        temperature=0.7,
        model="gpt-3.5-turbo"
    )

    system_prompt = """Tu es Flam√©o, un expert en s√©curit√© incendie qui aide √† r√©aliser des audits de b√¢timents. 
Tu es courtois, pr√©cis et tu parles fran√ßais. Tu dois collecter des informations sur le b√¢timent et √©valuer sa conformit√© aux normes de s√©curit√© incendie.

Voici les r√®gles √† suivre :
1. Un b√¢timent doit avoir au moins 1 extincteur pour 200 m¬≤
2. Un b√¢timent doit avoir au moins 2 sorties de secours
3. Chaque pi√®ce doit avoir un d√©tecteur de fum√©e
4. Les pi√®ces ne doivent pas d√©passer 50 m¬≤
5. Un plan d'√©vacuation doit √™tre affich√©
6. Au moins 2 sessions de formation doivent √™tre organis√©es par an

Quand tu as collect√© toutes les informations, tu dois √©valuer la conformit√© du b√¢timent et fournir des recommandations personnalis√©es."""

    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(system_prompt),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])

    memory = ConversationBufferMemory(return_messages=True, memory_key="history")
    conversation = ConversationChain(llm=llm, prompt=prompt, memory=memory, verbose=True)

    state = {}
    current_question_idx = 0
    audit_complete = False

    def extract_number(text):
        match = re.search(r'\b\d+\b', text)
        return int(match.group()) if match else None

    def convert_history(history):
        messages = []
        for entry in history:
            role = entry["role"]
            content = entry["content"]
            if role == "user":
                messages.append(HumanMessage(content=content))
            elif role == "assistant":
                messages.append(AIMessage(content=content))
        return messages

    def chat_fn(message, history):
        nonlocal current_question_idx, audit_complete

        # Convertir l'historique au format LangChain
        memory.chat_memory.messages = convert_history(history)

        if not history:
            return questions[0][0]

        if audit_complete:
            return conversation.predict(input=message)

        key = questions[current_question_idx][1]
        state[key] = message

        if key in ["buildingSize", "fireExtinguishers", "emergencyExits", "smokeDetectors", "roomCount", "trainingSessions", "staffAwareness"]:
            number = extract_number(message)
            if number is not None:
                state[key] = number
            else:
                clarification = conversation.predict(
                    input=f"L'utilisateur a r√©pondu '{message}' √† la question sur {key}. Je dois obtenir une valeur num√©rique. Reformule une question polie."
                )
                return clarification

        conversation.predict(input=f"Question: {questions[current_question_idx][0]}, R√©ponse: {message}")
        current_question_idx += 1

        if current_question_idx >= len(questions):
            audit_complete = True
            try:
                room_sizes = [float(size.strip()) for size in state.get("roomSizes", "").split(",")]
                state["roomSizes"] = room_sizes
            except Exception:
                state["roomSizes"] = []

            result = evaluate_audit(state)

            conversation.predict(
                input=f"""
                R√©sultat de l'audit:
                Status: {result.status}
                Message: {result.message}
                Recommandations: {result.recommendations}
                """
            )

            response = conversation.predict(
                input=f"""
                Voici les r√©sultats de l'audit du b√¢timent {state.get('buildingName', '')}.
                Statut: {result.status}
                {result.message}
                Recommandations :
                {result.recommendations}
                """
            )
            return response

        next_question = conversation.predict(
            input=f"Je dois poser la question suivante : {questions[current_question_idx][0]}. Personnalise-la si n√©cessaire."
        )

        return next_question

    with gr.Blocks() as demo:
        gr.Markdown("## üë©‚Äçüöí Flam√©o - Votre auditeur s√©curit√© incendie\nR√©pondez aux questions pour auditer votre b√¢timent.")
        gr.ChatInterface(chat_fn, chatbot=gr.Chatbot(type="messages"))
        gr.Button("‚¨ÖÔ∏è Retour √† l'accueil").click(
            None, None, None,
            js="window.location.href='/'"
        )

    return demo

# Gradio mont√© sur /audit-bot
app = gr.mount_gradio_app(app, audit_chatbot(), path="/audit-bot")
